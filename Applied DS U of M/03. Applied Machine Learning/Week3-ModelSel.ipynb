{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL SELECTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model selection is generally done through the use of cross-validations, validations curves, etc, in order to find a nominal, average performance for a model before we decide to train it / implement.\n",
    "\n",
    "Cross-validation works with accuracy by default, but we can also make it work across other metrics such as AUC (Area under the curve of ROC curves), Recall, Precision, etc. With this setting change we can find out which model suits best our business or overall objectives. To use a different metric we just need the scoring parameter on the cross-validation class creator. The list of valid scorers is found below.\n",
    "\n",
    "Then once we have found the best model based on our KPI of interest, we can proceed to find the best tuning parameter for that model via Gridsearch.\n",
    "Gridsearch allows us to test a specific parameters and find the values which maximize / optimize our target KPI.\n",
    "Gridsearch, just like cross_val, also looks for accuracy by default, but we can also check for other parameters.\n",
    "\n",
    "To prevent Data Leakage (test set info accidentaly being passed into the estimator during training) a good practice is to create 3 sets\n",
    "- Training set\n",
    "- Validation Set\n",
    "- Test set\n",
    "\n",
    "In practice, what is done is:\n",
    "\n",
    "1-) We create a normal train/test split\n",
    "2-) We perform the cross-validation / gridsearch based on training data BEFORE training the estimator. We use this to select model / parameter tuning.\n",
    "3-) After training the chosen estimator, we validate vs the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance\n",
      "r2\n",
      "max_error\n",
      "neg_median_absolute_error\n",
      "neg_mean_absolute_error\n",
      "neg_mean_absolute_percentage_error\n",
      "neg_mean_squared_error\n",
      "neg_mean_squared_log_error\n",
      "neg_root_mean_squared_error\n",
      "neg_mean_poisson_deviance\n",
      "neg_mean_gamma_deviance\n",
      "accuracy\n",
      "top_k_accuracy\n",
      "roc_auc\n",
      "roc_auc_ovr\n",
      "roc_auc_ovo\n",
      "roc_auc_ovr_weighted\n",
      "roc_auc_ovo_weighted\n",
      "balanced_accuracy\n",
      "average_precision\n",
      "neg_log_loss\n",
      "neg_brier_score\n",
      "adjusted_rand_score\n",
      "rand_score\n",
      "homogeneity_score\n",
      "completeness_score\n",
      "v_measure_score\n",
      "mutual_info_score\n",
      "adjusted_mutual_info_score\n",
      "normalized_mutual_info_score\n",
      "fowlkes_mallows_score\n",
      "precision\n",
      "precision_macro\n",
      "precision_micro\n",
      "precision_samples\n",
      "precision_weighted\n",
      "recall\n",
      "recall_macro\n",
      "recall_micro\n",
      "recall_samples\n",
      "recall_weighted\n",
      "f1\n",
      "f1_macro\n",
      "f1_micro\n",
      "f1_samples\n",
      "f1_weighted\n",
      "jaccard\n",
      "jaccard_macro\n",
      "jaccard_micro\n",
      "jaccard_samples\n",
      "jaccard_weighted\n"
     ]
    }
   ],
   "source": [
    "# The available scorers are\n",
    "from sklearn.metrics._scorer import SCORERS\n",
    "\n",
    "print(*list(SCORERS.keys()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the regular class\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel=\"linear\", C=1)\n",
    "\n",
    "# this one uses the default accuracy parameter\n",
    "acc_scores = cross_val_score(clf, X_train, y_train)\n",
    "recall_scores = cross_val_score(clf, X_train, y_train, scoring=\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID-SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the class\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = SVC(kernel=\"rbf\", C=1)\n",
    "\n",
    "# next, we set the relevant parameter we wish to test\n",
    "grid_param = {\"gamma\": [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# then we instatiate the relevant gridsearch as if it was the estimator\n",
    "grid_clf = GridSearchCV(clf, param_grid=grid_param)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "# then, we calculate all the resultng values\n",
    "y_decision_scores_acc = grid_clf.decision_function(X_test)\n",
    "\n",
    "# finally, we retrieve the optimized parameter AND the best score\n",
    "grid_clf.best_params_\n",
    "grid_clf.best_score_\n",
    "\n",
    "### ---------------------- TO USE A DIFFERENT SCORING PARAMETER, EXAMPLE BELOW ----------------------------------------------\n",
    "\n",
    "# then we instatiate the relevant gridsearch as if it was the estimator\n",
    "grid_clf = GridSearchCV(clf, param_grid=grid_param, scoring=\"precision\")\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "# then, we calculate all the resultng values\n",
    "y_decision_scores_acc = grid_clf.decision_function(X_test)\n",
    "\n",
    "# finally, we retrieve the optimized parameter AND the best score\n",
    "grid_clf.best_params_\n",
    "grid_clf.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
