{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "black-madonna",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS - MLP (MULTI LAYER PERCEPTRON)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "partial-briefing",
   "metadata": {},
   "source": [
    "Neural networks are broad family of algorithms that work on the idea of replicating the neural functioning of the brain.\n",
    "\n",
    "Neural networks are based on linear models in the sense that each input feature is given a weight, or importance, as part of the tuning process. MLPs add a hidden layer, with many hidden units inside, to this process which allow the algorithm to learn and/or  more complex behaviour. \n",
    "\n",
    "The hidden units are the key to MLPs.\n",
    "Hidden units, just like normal features in a linear regression, are given a weight which is used to determine their importance and estblishing the final value of the prediction. Hidden units are characterized by having an ACTIVATION FUNCTION, which is a function that determines WHEN the hidden unit is activated (Non 0 value)\n",
    "By default MLPs work with 1 hidden layer, but we can set more hidden layers.\n",
    "\n",
    "Neural networks are very good at learning complex, non-linear behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seasonal-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the necessary class\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# we instance the classifier and designate its key parameters\n",
    "    ## The hidden layer sizes, as a list. The number on the list si the number of hidden units. If we pass more than 1 list element, we set many hidden LAYERS.\n",
    "    ## solver; the algorithm to approximately the solution\n",
    "    ## alpha; regularization factor. The higher the alpha, the more regularization and the 'simpler' the model.\n",
    "    ## activation; the activation function. The options are RELU, TANH.\n",
    "clf = MLPClassifier(hidden_layer_sizes=[100], solver=\"lbfgs\", alpha=1, activation=\"tanh\")\n",
    "    ## example with TWO hidden layer\n",
    "clf = MLPClassifier(hidden_layer_sizes=[100,100], solver=\"lbfgs\")\n",
    "\n",
    "# then, like other models, we fit the model to the training data.\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-arcade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
