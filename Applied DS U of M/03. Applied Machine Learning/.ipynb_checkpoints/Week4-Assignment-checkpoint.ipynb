{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# autocomplete fix because IPYTHON UGH\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-catholic",
   "metadata": {},
   "source": [
    "# DATA LOAD AND EXPLORATORY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "careful-killing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22056</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27586</td>\n",
       "      <td>750.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22062</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22084</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22093</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id  fine_amount  admin_fee  state_fee  discount_amount  \\\n",
       "0      22056        250.0       20.0       10.0              0.0   \n",
       "1      27586        750.0       20.0       10.0              0.0   \n",
       "2      22062        250.0        0.0        0.0              0.0   \n",
       "3      22084        250.0        0.0        0.0              0.0   \n",
       "4      22093        250.0        0.0        0.0              0.0   \n",
       "\n",
       "   judgment_amount  compliance  \n",
       "0            305.0         0.0  \n",
       "1            855.0         1.0  \n",
       "2              0.0         NaN  \n",
       "3              0.0         NaN  \n",
       "4              0.0         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA DELETION\n",
    "\n",
    "    ## columns 12 and 31 have noise (most of them are NaN with 1 or 2 exceptions) I will delete these columns sa well since their data is noise.\n",
    "\n",
    "    # as a matter of principle our train / test data should have the same amount of input features, thus, I will delete all columns not present in test.csv.\n",
    "        ## exception, obviously I will keep the target value.\n",
    "\n",
    "    # to NOT include -> payment_amount, payment_date, payment_status, balance_due, collection_status, compliance_detail\n",
    "    # to NOT include 2 -> violation_zip_code : Data is all NaN.\n",
    "    # to NOT include 3 -> violator_name : Data is all unique names, not relevant\n",
    "    # to NOT include 4 -> since i'm deleting column 31, I will delete its associate column clean_up_cost. All of its values are 0.\n",
    "    # to NOT include 5 -> late_fee, since it provides information about the feature.\n",
    "    # to NOT include 6 -> 'mailing_address_str_number', 'mailing_address_str_name', . Sparse address information.\n",
    "    # to NOT inlcude 7 -> ignoring city, state, zip code and country.\n",
    "    # to NOT include 8 -> datetime columns -> they screw Gaussian NB\n",
    "    \n",
    "    # I'm going to ignore geographic latlon data pairs. its useless here and only adds noise.\n",
    "\n",
    "# DATA TRANSFORM\n",
    "    # column 11 is zip dates, this shouldnt be touched at all. Set to string.\n",
    "    # \"violation_street_number\" should be a string, but first i'll pass it as a string to get rid of annoying digits without having to format.\n",
    "    \n",
    "df = pd.read_csv(\"data/train.csv\", usecols=['ticket_id', 'fine_amount', 'admin_fee', 'state_fee',\n",
    "                            'discount_amount', 'judgment_amount', 'compliance'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continental-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating mask to eliminate all nan values in compliance\n",
    "not_na_mask = df[\"compliance\"].notna()\n",
    "df = df[not_na_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, i'll drop any remaining NAs and ticket id\n",
    "df = df.dropna()\n",
    "df = df.drop(\"ticket_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data \n",
    "X = df.drop(\"compliance\", axis=1)\n",
    "y = df[\"compliance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "banner-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nencoder = OneHotEncoder(sparse=False, dtype=int, handle_unknown=\"ignore\")\\nencoder.fit(X[[\\'agency_name\\', \\'inspector_name\\', \\'violation_code\\', \\'disposition\\']])\\nt = encoder.transform(X[[\\'agency_name\\', \\'inspector_name\\', \\'violation_code\\', \\'disposition\\']])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating transformation pipelina for all categorical columns\n",
    "    ## list(X.select_dtypes(\"object\").columns) gets me all the non numerical columns\n",
    "    \n",
    "# THIS METHOD IS VALID BUT BECAUSE OF THE OLD JUPYTER I CANT USE IT\n",
    "'''\n",
    "ct = ColumnTransformer(\n",
    "    [(\"encoder\", OneHotEncoder(sparse=False, dtype=\"int\", handle_unknown=\"ignore\"), list(X.select_dtypes(\"object\").columns))], remainder=\"passthrough\")\n",
    "'''\n",
    "# SCREW OLD DISTROOOS\n",
    "'''\n",
    "encoder = OneHotEncoder(sparse=False, dtype=int, handle_unknown=\"ignore\")\n",
    "encoder.fit(X[['agency_name', 'inspector_name', 'violation_code', 'disposition']])\n",
    "t = encoder.transform(X[['agency_name', 'inspector_name', 'violation_code', 'disposition']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-genome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX2 = np.concatenate((t, X[\"fine_amount\"].to_numpy().reshape(-1,1), X[\"admin_fee\"].to_numpy().reshape(-1,1), X[\"state_fee\"].to_numpy().reshape(-1,1),\\n                    X[\"discount_amount\"].to_numpy().reshape(-1,1), X[\"judgment_amount\"].to_numpy().reshape(-1,1))\\n                    , axis=1)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving array\n",
    "'''\n",
    "X2 = np.concatenate((t, X[\"fine_amount\"].to_numpy().reshape(-1,1), X[\"admin_fee\"].to_numpy().reshape(-1,1), X[\"state_fee\"].to_numpy().reshape(-1,1),\n",
    "                    X[\"discount_amount\"].to_numpy().reshape(-1,1), X[\"judgment_amount\"].to_numpy().reshape(-1,1))\n",
    "                    , axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nutritional-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "approved-enhancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting dummy classifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# determining baseline score with mf strategy\n",
    "roc_auc_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "short-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosted forest is best\n",
    "    # optimal params found via gridsearch\n",
    "clf3 = GradientBoostingClassifier(learning_rate=0.1, n_estimators=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "further-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595810964651488"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, clf3.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "personal-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing test df\n",
    "test_df = pd.read_csv(\"data/test.csv\", usecols=['ticket_id', 'fine_amount', 'admin_fee', 'state_fee',\n",
    "                            'discount_amount', 'judgment_amount'])\n",
    "\n",
    "# finally, dropping irrelevant nas\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "equal-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating tickets and delating from test df\n",
    "ticket = test_df[\"ticket_id\"]\n",
    "test_df = test_df.drop(\"ticket_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t2 = encoder.transform(test_df[['agency_name', 'inspector_name', 'violation_code', 'disposition']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "organizational-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_X = np.concatenate((t2, test_df[\"fine_amount\"].to_numpy().reshape(-1,1), test_df[\"admin_fee\"].to_numpy().reshape(-1,1), \\n                         test_df[\"state_fee\"].to_numpy().reshape(-1,1), test_df[\"discount_amount\"].to_numpy().reshape(-1,1),\\n                         test_df[\"judgment_amount\"].to_numpy().reshape(-1,1))\\n                    , axis=1)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test_X = np.concatenate((t2, test_df[\"fine_amount\"].to_numpy().reshape(-1,1), test_df[\"admin_fee\"].to_numpy().reshape(-1,1), \n",
    "                         test_df[\"state_fee\"].to_numpy().reshape(-1,1), test_df[\"discount_amount\"].to_numpy().reshape(-1,1),\n",
    "                         test_df[\"judgment_amount\"].to_numpy().reshape(-1,1))\n",
    "                    , axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "informal-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = clf3.predict_proba(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "upper-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(data=prob[:,0],index=ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "focal-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.938385\n",
       "285362    0.971450\n",
       "285361    0.927121\n",
       "285338    0.938385\n",
       "285346    0.927121\n",
       "            ...   \n",
       "376496    0.971450\n",
       "376497    0.971450\n",
       "376499    0.927121\n",
       "376500    0.927121\n",
       "369851    0.745046\n",
       "Length: 61001, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-pollution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
